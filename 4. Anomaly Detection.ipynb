{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomaly Detection :\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also called Outlier detection, could be used to detect samples which do not conform to an expected pattern or other items in a dataset.So when there is a classification or unsupervised learning problem (rare case identification), it could be helpful. So the following would be introduce how to build anomaly detection method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1, Define the notation:\n",
    "\n",
    "m-- Number of training samples\n",
    "\n",
    "n-- Number of sample features\n",
    "\n",
    "X-- Features (vector)\n",
    "\n",
    "$\\mu$-- mean\n",
    "\n",
    "$\\sigma^2$-- variance\n",
    "\n",
    "$\\epsilon$-- threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2, Gaussian distribution:\n",
    "\n",
    "To perform anomaly detection, you will first need to fit a model to the data's\n",
    "distribution.\n",
    "\n",
    "Given a training data set, you could estimate the Gaussian distribution for each of the features. \n",
    "<img src=\"https://github.com/GongliDuan/exdata-data-household_power_consumption/blob/master/1.png?raw=true\" alt=\"1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3, Estimating parameters for a Gaussian:\n",
    "\n",
    "In the Gaussian distribution, to estimate the mean, you will use:\n",
    "<img src=\"https://github.com/GongliDuan/exdata-data-household_power_consumption/blob/master/2.png?raw=true\" alt=\"2.png\">\n",
    "\n",
    "And for the variance you will use:\n",
    "<img src=\"https://github.com/GongliDuan/exdata-data-household_power_consumption/blob/master/3.png?raw=true\" alt=\"3.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4, F-1 score:\n",
    "\n",
    "tp: is the number of true positives: the ground truth label says it's an anomaly and our algorithm correctly classified it as an anomaly.\n",
    "\n",
    "fp: is the number of false positives: the ground truth label says it's not an anomaly, but our algorithm incorrectly classified it as an anomaly.\n",
    "\n",
    "fn: is the number of false negatives: the ground truth label says it's ananomaly, but our algorithm incorrectly classified it as not being anomalous.\n",
    "\n",
    "precision:\n",
    "<img src=\"https://github.com/GongliDuan/exdata-data-household_power_consumption/blob/master/4.png?raw=true\" alt=\"4.png\">\n",
    "\n",
    "recall:\n",
    "<img src=\"https://github.com/GongliDuan/exdata-data-household_power_consumption/blob/master/5.png?raw=true\" alt=\"5.png\">\n",
    "\n",
    "F1 score:\n",
    "<img src=\"https://github.com/GongliDuan/exdata-data-household_power_consumption/blob/master/6.png?raw=true\" alt=\"6.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5, Selecting the threshold:\n",
    "\n",
    "After we build the Gaussian distribution formula, when there is a new test sample, we could put it in and get the p. If p<$\\epsilon$, we will count it as an anomaly one. \n",
    "\n",
    "So we could know, it's a key setp to choose the value of $\\epsilon$. We can do this by borrowing the idea of cross-validation from supervised learning. \n",
    "\n",
    "Assume we have m-1 normal samples, and m-2 abnormal samples. We can split m1 into three sub set, m-11, m-12, m-13, meantime divide m-2 into m-21 and m-22. Then, we can use m-11 to calculate mean and variance, so we would have the Gaussian distribution. After that, we can combine m-12 and m-21, assign targets to them. m-12 as 0 and m-21 as 1. We loop through a list of possible $\\epsilon$ values, for each one there is corresponding result on detection. F1 score could be used to judge which $\\epsilon$ value is the most proper. In the end, m-13 and m-22 samples are left for test. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The following is the module built by python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "class Anomaly_Detection():\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.mu = None\n",
    "        self.sigma2 = None\n",
    "        self.best_epsilon = 0\n",
    "        self.best_f1_score = 0\n",
    "\n",
    "    def gaussian_para(self, X):\n",
    "        #get the mean and variance from a sub set of normal training data set \n",
    "        self.mu = np.mean(X, axis=0)\n",
    "        self.sigma2 = np.var(X, axis=0)\n",
    "        \n",
    "    def gaussian(self, X):\n",
    "        # calculate the Gaussian distribution \n",
    "        p=np.prod(np.exp(-1.0*(X - self.mu)**2 / (2.0 * self.sigma2) ) / np.sqrt(2.0 * math.pi * self.sigma2) , axis=1)\n",
    "        return p\n",
    "    \n",
    "    def fit_epsilon(self, X, y):\n",
    "        # by 2nd normal training data sub set and 1st abnormal training data sub set,\n",
    "        # through a for loop, to search the proper epsilon value.\n",
    "        # use f1 score, to value the performance and define epsilon\n",
    "        p_value = self.gaussian(X)\n",
    "        p_max = max(p_value)\n",
    "        p_min = min(p_value)\n",
    "        step = (p_max-p_min) / 100.0\n",
    "        \n",
    "        for epsilon in np.arange(p_min, p_max + step, step):\n",
    "            y_val= (p_value < epsilon).astype(int)\n",
    "            tp = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            for i in range(0,len(y_val)):\n",
    "                if y_val[i]==1 and y[i]==1:\n",
    "                    tp=tp+1\n",
    "                if y_val[i]==1 and y[i]==0:\n",
    "                    fp=fp+1\n",
    "                if y_val[i]==0 and y[i]==1:\n",
    "                    fn=fn+1\n",
    "                    \n",
    "                if tp==0 and fp==0:\n",
    "                    continue\n",
    "                if tp==0 and fn==0:\n",
    "                    continue\n",
    "\n",
    "                prec = float(tp)/(tp+fp)\n",
    "                rec = float(tp)/(tp+fn)\n",
    "                f1 = 2*prec*rec/(prec+rec)\n",
    "                \n",
    "                if f1 > self.best_f1_score:\n",
    "                    self.best_f1_score=f1\n",
    "                    self.best_epsilon=epsilon\n",
    "            \n",
    "    def fit(self, X_train, X_val, y_val):\n",
    "        # training to get the module\n",
    "        self.gaussian_para(X_train)\n",
    "        self.fit_epsilon(X_val, y_val)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        # forecast the test samples, to find which of them are normal and which are not.\n",
    "        # in result array, 0 represents normal, 1 means abnormal\n",
    "        p=self.gaussian(X)\n",
    "        y=(p < self.best_epsilon).astype(int)\n",
    "        return y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
